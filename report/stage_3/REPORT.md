# 2021-highload-dht

Курсовой проект в рамках обучающей программы "[Технополис](https://polis.mail.ru)" по дисциплине [Высоконагруженные вычисления](https://polis.mail.ru/curriculum/program/discipline/1257/).

## Этап 3. Многопоточность

Для тестирования с помощью wrk2 были подобраны оптимальные параметры для тестируемого
железа (процессор: AMD 5800H 8 ядер / 16 потоков, RAM: 16Гб, SSD NVMe).
Скрипт запуска можно увидеть тут: [wrk2.sh](../../profiling/wrk2.sh).
Все тесты проводились на одних и тех же параметрах.

### [Синхронный сервер](https://github.com/CRaFT4ik/2021-highload-dht/blob/stage_2/src/main/java/ru/mail/polis/service/eldar_tim/HttpServerImpl.java)

Возьмем сервер, имеющийся на конец второго этапа, и произведем его профилирование.
В синхронной реализации потоки-селекторы выполняют всю работу по вставке
и извлечению данных самостоятельно.

- [wrk2 PUT](profiling/sync/wrk2_sync2_put.txt)
- [wrk2 GET](profiling/sync/wrk2_sync2_get.txt)
- [async-profiler CPU](profiling/sync/profiler_cpu_sync2.html)
- [async-profiler ALLOC](profiling/sync/profiler_alloc_sync2.html)
- [async-profiler LOCK](profiling/sync/profiler_lock_sync2.html)

### [Асинхронный сервер](https://github.com/CRaFT4ik/2021-highload-dht/blob/stage_3/src/main/java/ru/mail/polis/service/eldar_tim/HttpServerImpl.java)

На данном этапе возникло множество вопросов, которые я задал кураторам проекта.
Меня попросили продублировать мои рассуждения в отчете. Приведу их по ходу изложения.

Идея асинхронного сервера, реализуемого на данном этапе, строится на том, чтобы
освободить пул потоков селекторов, делегируя полезную работу пулу рабочих потоков.
Селекторы могут работать быстрее рабочих, поэтому необходимо ограничить очередь задач
для пула рабочих, чтобы уменьшить конечное время ответа и не перегружать сервер.
Отсекаемым запросам необходимо возвращать 503 ошибку.

#### Реализация на блокирующей очереди

Было принято решение использовать `ThreadPoolExecutor`, который предоставляет нам 
право выбора `BlockingQueue` для организации очереди работ. Выбрана реализация
`LinkedBlockingQueue`. Лимит этой очереди в процессе многочисленных тестов
устанавливался разным: 32, 128 и 1000 элементов. Пул рабочих равен количеству потоков,
одновременно поддерживаемых процессором (16).

В результате получилось, что ни один из устанавливаемых лимитов очереди 
не показал производительность лучше, чем синхронная обработка запросов.

Результаты измерений **асинхронной** реализации на лимите очереди 1000:
 - [wrk2 PUT](profiling/async/threadpool/wrk2_workers2_put.txt)
 - [wrk2 GET](profiling/async/threadpool/wrk2_workers2_get.txt)
 - [async-profiler CPU](profiling/async/threadpool/profiler_cpu_workers2.html)
 - [async-profiler ALLOC](profiling/async/threadpool/profiler_alloc_workers2.html)
 - [async-profiler LOCK](profiling/async/threadpool/profiler_lock_workers2.html)

Note: Результаты измерений **синхронной** реализации приведены выше.

Из сравнения результатов wrk2 видим, что синхронная реализация работает быстрее.
Да, при таком лимите мы все ещё не отсекаем чрезмерную нагрузку (нет 2xx и 3xx ответов).

Попробуем уменьшить очередь до 128:
- [wrk2 PUT](profiling/async/threadpool/wrk2_workers128_put.txt)
- [wrk2 GET](profiling/async/threadpool/wrk2_workers128_get.txt)

Видим результаты ещё хуже. Производительность упала, и это при том, 
что уже почти 100_000 запросов было отсечено. Что-то тут не так:
взглянем на профиль LOCK и поймем в чем дело. Потоки-рабочие очень много вызывают
`LinkedBlockingQueue.take()` и застревают на нем на какое-то время, что
приводит к задержкам.

Уменьшим очередь ещё сильнее (до 32):
- [wrk2 PUT](profiling/async/threadpool/wrk2_workers32_put.txt)
- [wrk2 GET](profiling/async/threadpool/wrk2_workers32_get.txt)

Все встало на свои места? Вроде бы да. Я так и подумал, пока не сделал
ещё несколько тестов подряд. Результат был нестабилен, и на 99.999 - 100 перцентилях
появились резкие скачки вплоть до 200 мс.

Поэтому было решено отказаться от `ThreadPoolExecutor` и его блокирующей очереди 
в пользу другого решения.

#### Реализация без блокирующих очередей

Я решил использовать в качестве исполнителя `ForkJoinPool`, который не использует общую
блокирующую очередь. 
Также я не планировал использовать никакие `fork()` и `join()`, предоставляемый этим
сервисом, поскольку задачи-запросы уже итак поделены и самодостаточны.
Вместо этого установил флаг `asyncMode` в конструкторе `ForkJoinPool`:

```
asyncMode – if true, establishes local first-in-first-out scheduling mode
for forked tasks that are never joined. This mode may be more appropriate
than default locally stack-based mode in applications in which worker threads
only process event-style asynchronous tasks. For default value, use false.
```

Встал вопрос, как отсекать лишние запросы, когда нет очереди.
В ответ на это, я решил ввести атомарный счетчик [в своем сервисе-исполнителе](https://github.com/CRaFT4ik/2021-highload-dht/blob/stage_3/src/main/java/ru/mail/polis/service/eldar_tim/LimitedServiceExecutor.java),
имитирующий очередь.
Ни один поток не блокируется, пока инкриминирует или проверяет его. Такой подход
показал наибольшую производительность.

Результаты измерений для асинхронной реализации (лимит очереди - 32 элемента):

- [wrk2 PUT](profiling/async/forkjoinpool/wrk2_workers32_put.txt)
- [wrk2 GET](profiling/async/forkjoinpool/wrk2_workers32_get.txt)
- [async-profiler CPU](profiling/async/forkjoinpool/profiler_cpu_workers32.html)
- [async-profiler ALLOC](profiling/async/forkjoinpool/profiler_alloc_workers32.html)
- [async-profiler LOCK](profiling/async/forkjoinpool/profiler_lock_workers32.html)

Видим, что не так много запросов (по сравнению с общим количеством) было отсечено.
Но отсечения есть, а это значит реализация работает, и работает корректно.

Теперь перейдем к самому интересному - к сравнению времени ответа сервера. Среднее время
ответа было уменьшено на сотые доли, что кажется не таким большим достижением.
Однако, что интересно, для 99.99 - 100 перцентилей время ответа было уменьшено в 2 раза.
Это похоже на хороший результат.

### Выводы
 - Разгрузили селекторы;
 - Добавили механизм отсечения чрезмерной нагрузки;
 - Результаты измерений после проведенных улучшений говорят о снижении как среднего времени
ответа сервера, так и конкретно последних перцентилей (для них в 2 раза);
 - Практически весь профиль LOCK занимает синхронизация на отправке ответа в HttpSession.
В остальном этот профиль свободен, недочетов не обнаружено;
 - Достаточно много аллокаций делают операции с итераторами и методы по работе
с HTTP протоколом;
 - Профиль CPU занимает примерно на 40% код полезной нагрузки по чтению данных,
20% занимает код селекторов по работе с сокетами и около 25% CPU занимает запись 
в сокет рабочим пулом потоков;

---

Вопросы, которые возникали по ходу работы, и ответы на них:

1. Логично было бы, чтобы именно селекторы занимались записью в сокет после того, как рабочие обработали
запросы. Задался вопросом, возможно ли вернуть им управление? Я пытался, но у меня не возникло идей как это сделать.
**UPD:** Кураторы проекта мне ответили, что нет необходимости это делать.
2. Получается так, что код выполняется быстрее в старой реализации, когда селекторы делали всю работу. 
Разница была ощутима. Я подозревал, что пока происходит передача управления между потоками, возникает 
существенная задержка. **UPD:** Действительно, синхронизация потоков на очереди вызывала задержки. 
3. Когда очередь задач на выполнение переполняется, я пробовал 2 вещи. Первое - отправлять в ответ 503 ошибку прямо
из потока селектора, второе (безысходность) - session.scheduleClose(). Казалось бы, отсекаем лишние запросы и не лезем 
в LsmDAO. Но оба варианта не приводили к улучшению производительности, даже наоборот.
**UPD:** Проблема была опять же, в пункте 2.
